<html>
  <head>
    <meta content="text/html;charset=utf-8" http-equiv="Content-Type"/>

    <title>t420babe demo core</title>
  </head>
  <body>
    <h1>t420babe demo core</h1>

    <audio id="audio-src" src="./02-fade.mp3"></audio>
    <div>
    <button id="play-pause" data-playing="false" role="switch" aria-checked="false">
      <span>Play/Pause</span>
    </button>
    </div>


    <!-- DONT DELETE THIS BEGIN -->
    <div>
      <canvas id="canvas" height="500" width="500" />
    </div>
    <!-- DONT DELETE THIS END -->
<script>

  let audio = new AudioContext();
  // node that does fft
  let node = audio.createAnalyser();

  // object that represents microphone
  (async () => { 
    // get microphone input(video or audio)
   let stream = await navigator.mediaDevices.getUserMedia({
      video: false,
      audio: {
        noiseSuppression: false,
        echoCancellation: false,
      }
    });
    // input audio node
    let audioNode = audio.createMediaStreamSource(stream);
    // now connect to analyzer
    audioNode.connect(node);

    // can put this outside of async
    // want animation loop, use request animation frames
    requestAnimationFrame(drawLoop);
  })();

  // create buffer

  // decide how big want buffer to be to hold fft
  let kMaxFrequency = 20000;
  let buffer = new Uint8Array(Math.floor(kMaxFrequency / audio.sampleRate * (node.fftSize / 2)));

  const drawLoop = () => {
    node.getByteFrequencyData(buffer);
    console.log(buffer);
    requestAnimationFrame(drawLoop);
  }

</script>

  </body>
</html>


